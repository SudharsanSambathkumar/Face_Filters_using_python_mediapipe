{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1ea4a2d-eba8-4d59-9b04-8f90d5c62ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ff7439b-87bc-458c-a40c-6a4b0a6cc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Mesh and MediaPipe Hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fffb8d18-9913-400d-b652-ff0ff06ae43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_four_channels(image):\n",
    "    if len(image.shape) == 2:  # Grayscale image\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2BGRA)\n",
    "    elif image.shape[2] == 3:  # Image without alpha channel\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    return image  # Image already has alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e91609-1e68-42f5-8ca6-331dab999a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice=int(input('1:Deadpool\\n2:Wolverine\\nEnter your choice:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eac82de-d3d0-4bfd-9623-d46e02cc8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image to overlay\n",
    "if choice==1:\n",
    "    overlay_hand_image = cv2.imread('images/shield_1.png', cv2.IMREAD_UNCHANGED)\n",
    "    overlay_face_image = cv2.imread('images/deadpool1.png', cv2.IMREAD_UNCHANGED)\n",
    "    ar=[9]# one shield\n",
    "    head_size=2\n",
    "else:\n",
    "    overlay_hand_image = cv2.imread('images/claw_1.png', cv2.IMREAD_UNCHANGED)\n",
    "    overlay_face_image = cv2.imread('images/wolverine_3.png', cv2.IMREAD_UNCHANGED)\n",
    "    ar=[5,9,13]#claws in three fingers\n",
    "    head_size=3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17c8a91a-19d9-4d16-97e0-498fbbfd5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_hand_image = ensure_four_channels(overlay_hand_image)\n",
    "overlay_face_image = ensure_four_channels(overlay_face_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab3a551a-c7a4-4b4a-831e-a6147ea963b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709, 709, 4)\n",
      "(440, 249, 4)\n"
     ]
    }
   ],
   "source": [
    "print(overlay_hand_image.shape)\n",
    "print(overlay_face_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18a8240e-a48b-4aa0-b6b1-13fdb2783625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the hand is closed (simple example)\n",
    "def is_hand_closed(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y\n",
    "    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y\n",
    "    return thumb_tip < index_finger_tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d8e22e2-6700-432a-8a2d-3389278ef3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    # Compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "    # Adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - center[0]\n",
    "    M[1, 2] += (nH / 2) - center[1]\n",
    "    # Perform the actual rotation and return the image\n",
    "    rotated = cv2.warpAffine(image, M, (nW, nH), flags=cv2.INTER_LINEAR)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b86187cc-9aae-4532-acde-a7e0fb86e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_on_face(image, overlay, landmarks):\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Get coordinates for the eyes\n",
    "    left_eye = landmarks[33]  # Landmark for the left eye\n",
    "    right_eye = landmarks[263]  # Landmark for the right eye\n",
    "\n",
    "    # Calculate the center between the eyes\n",
    "    center_x = int((left_eye[0] + right_eye[0]) / 2)\n",
    "    center_y = int((left_eye[1] + right_eye[1]) / 2)\n",
    "\n",
    "    # Calculate width and height for the overlay\n",
    "    overlay_width = int(np.linalg.norm(right_eye - left_eye) * head_size)\n",
    "    aspect_ratio = overlay.shape[0] / overlay.shape[1]  # Height / Width of the overlay image\n",
    "    overlay_height = int(overlay_width * aspect_ratio)\n",
    "\n",
    "    # Calculate the angle between the eyes (in degrees)\n",
    "    angle = -np.degrees(np.arctan2(right_eye[1] - left_eye[1], right_eye[0] - left_eye[0]))\n",
    "\n",
    "    # Resize overlay\n",
    "    overlay_resized = cv2.resize(overlay, (overlay_width, overlay_height))\n",
    "\n",
    "    # Rotate overlay\n",
    "    overlay_resized = rotate_image(overlay_resized, angle)\n",
    "\n",
    "    # Calculate the new dimensions of the rotated overlay\n",
    "    oh, ow, _ = overlay_resized.shape\n",
    "\n",
    "    # Calculate top-left corner of the overlay\n",
    "    top_left_x = center_x - ow//2\n",
    "    top_left_y = center_y - oh//2\n",
    "\n",
    "    # Ensure the coordinates are within the image dimensions\n",
    "    if top_left_x < 0 or top_left_y < 0 or top_left_x + ow > w or top_left_y + oh > h:\n",
    "        return image\n",
    "\n",
    "    # Split channels\n",
    "    overlay_rgb = overlay_resized[:, :, :3]\n",
    "    overlay_alpha = overlay_resized[:, :, 3] / 255.0\n",
    "\n",
    "    # Get region of interest\n",
    "    roi = image[top_left_y:top_left_y + oh, top_left_x:top_left_x + ow]\n",
    "\n",
    "    # Blend the overlay with the ROI\n",
    "    for c in range(3):\n",
    "        roi[:, :, c] = (1.0 - overlay_alpha) * roi[:, :, c] + overlay_alpha * overlay_rgb[:, :, c]\n",
    "\n",
    "    image[top_left_y:top_left_y + oh, top_left_x:top_left_x + ow] = roi\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c77e2f7f-bad8-4098-9155-7aa2cf50a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_on_hand(background, overlay, x, y):\n",
    "    bg_h, bg_w, bg_channels = background.shape\n",
    "    if bg_channels == 3:\n",
    "        background = cv2.cvtColor(background, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    overlay_h, overlay_w, overlay_channels = overlay.shape\n",
    "\n",
    "    # Ensure the coordinates are within bounds\n",
    "    if x >= bg_w or y >= bg_h or x + overlay_w <= 0 or y + overlay_h <= 0:\n",
    "        return background\n",
    "\n",
    "    # Clip overlay dimensions to fit within the background\n",
    "    if x + overlay_w > bg_w:\n",
    "        overlay_w = bg_w - x\n",
    "        overlay = overlay[:, :overlay_w]\n",
    "\n",
    "    if y + overlay_h > bg_h:\n",
    "        overlay_h = bg_h - y\n",
    "        overlay = overlay[:overlay_h]\n",
    "\n",
    "    if x < 0:\n",
    "        overlay = overlay[:, -x:]\n",
    "        overlay_w = overlay.shape[1]\n",
    "        x = 0\n",
    "\n",
    "    if y < 0:\n",
    "        overlay = overlay[-y:, :]\n",
    "        overlay_h = overlay.shape[0]\n",
    "        y = 0\n",
    "\n",
    "    if overlay_w <= 0 or overlay_h <= 0:\n",
    "        return background\n",
    "\n",
    "    overlay_image = overlay[:overlay_h, :overlay_w]\n",
    "\n",
    "     \n",
    "\n",
    "    # Apply the fade mask to the overlay image\n",
    "    overlay_image = overlay_image.astype(np.float32)\n",
    "    if choice==2:\n",
    "        # Create a fade mask for the bottom half\n",
    "        fade_mask_height = overlay_h // 2\n",
    "        fade_mask = np.ones((overlay_h, overlay_w), dtype=np.float32)\n",
    "        fade_values = np.linspace(1, 0, fade_mask_height)**6\n",
    "        fade_mask[-fade_mask_height:] = np.tile(fade_values.reshape(-1, 1), (1, overlay_w))\n",
    "    \n",
    "        fade_mask = np.dstack((fade_mask, fade_mask, fade_mask, fade_mask))  # Repeat for all channels\n",
    "        overlay_image[:, :, 3] = overlay_image[:, :, 3] * fade_mask[:, :, 3]\n",
    "    else:\n",
    "        overlay_image[:, :, 3] = overlay_image[:, :, 3] \n",
    "\n",
    "\n",
    "    mask = overlay_image[:, :, 3:] / 255.0\n",
    "    background[y:y+overlay_h, x:x+overlay_w, :3] = (1.0 - mask) * background[y:y+overlay_h, x:x+overlay_w, :3] + mask * overlay_image[:, :, :3]\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eddf9b72-f3ca-4250-8425-392c23f87145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hand_tracking_and_face_mesh(cap, overlay_image_hand, overlay_image_face):\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5) as face_mesh, mp_hands.Hands(\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results_face = face_mesh.process(frame)\n",
    "            results_hand = hands.process(frame)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Overlay face mesh\n",
    "            if results_face.multi_face_landmarks:\n",
    "                for face_landmarks in results_face.multi_face_landmarks:\n",
    "                    landmarks = np.array([[lm.x * frame.shape[1], lm.y * frame.shape[0]] for lm in face_landmarks.landmark])\n",
    "                    frame = overlay_on_face(frame, overlay_image_face, landmarks)\n",
    "\n",
    "            # Overlay hand mesh\n",
    "            if results_hand.multi_hand_landmarks:\n",
    "                \n",
    "                for hand_landmarks in results_hand.multi_hand_landmarks:\n",
    "                    \n",
    "                    if is_hand_closed(hand_landmarks):\n",
    "                        \n",
    "                        wrist_x = int(hand_landmarks.landmark[0].x * frame.shape[1])\n",
    "                        wrist_y = int(hand_landmarks.landmark[0].y * frame.shape[0])\n",
    "\n",
    "                        for i in ar:\n",
    "                            mcp_x = int(hand_landmarks.landmark[i].x * frame.shape[1])\n",
    "                            mcp_y = int(hand_landmarks.landmark[i].y * frame.shape[0])\n",
    "\n",
    "                            delta_x = wrist_x - mcp_x\n",
    "                            delta_y = mcp_y - wrist_y\n",
    "                            angle = np.arctan2(delta_y, delta_x) * 180.0 / np.pi\n",
    "\n",
    "                            scale_factor = 0.4\n",
    "                            overlay_resized = cv2.resize(overlay_image_hand, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "                            overlay_rotated = rotate_image(overlay_resized, angle+90)\n",
    "\n",
    "                            overlay_h, overlay_w = overlay_rotated.shape[:2]\n",
    "                            x = mcp_x - overlay_w // 2\n",
    "                            y = mcp_y - overlay_h // 2\n",
    "                            frame = overlay_on_hand(frame, overlay_rotated, x, y)\n",
    "                    \n",
    "\n",
    "            cv2.imshow('Hand and Face Mesh Overlay', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6b97cc6-691e-419d-ada6-7ef847c0302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "process_hand_tracking_and_face_mesh(cap, overlay_hand_image, overlay_face_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
